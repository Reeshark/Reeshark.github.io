---
permalink: /
title: "About Me"
excerpt: "Cong Ma (马璁)"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am Cong Ma (马璁), and I obtained my Ph.D. degree from [National Engineering Research Center of Visual Technology, Peking University](https://idm.pku.edu.cn/en) in 2021 advised by Prof. [Xiaidong Xie](https://scholar.google.com/citations?user=9-s2WI8AAAAJ&hl=en&oi=ao) and Prof. [Wen Gao](https://scholar.google.com/citations?user=u9aw5o8AAAAJ&hl=en&oi=ao). I completed my bachelor's degree at [School of Artificial Intelligence, Xidian University](https://sai.xidian.edu.cn/) in 2016 supervised by Prof. [Licheng Jiao](https://scholar.google.com/citations?user=FZbrL2YAAAAJ&hl=en&oi=ao). I received a visiting student researcher position at [Stanford Vision and Learning Lab](https://svl.stanford.edu/) under the supervision of Prof. [Silvio Savarese](https://scholar.google.com/citations?hl=en&user=ImpbxLsAAAAJ) in 2020. 

Currently, I am working at [Sensetime](https://www.sensetime.com/en) where I lead a team dedicated to researching the Roadside Holographic Intersection Perception Algorithm such as 2D/Monocular 3D Detection, Lidar 3D Detection, Multi-Object Tracking, and Multi-Sensor Fusion. In addition to this role, I also serves as the Chief Technical Adviser for projects involving Smart-Surveillance Systems, Intelligent Transportation and Vehicle-Infrastructure Cooperation. I am leading a team consisting of two full-time employees, two internships, and six students, who are all dedicated to advancing the field of our projects. Together, we have been actively involved in cutting-edge research. 

In addition to my research contributions, I have served as a reviewer for prestigious journals and conferences, including IJCV, PR, TIP, TCSVT, AAAI, and ECCV and have reviewed a total of 24 papers. I was nominated for the prestigious ["Person of the Year"](http://stu.people.com.cn/GB/n1/2016/0429/c402103-28314575.html) award in 2016 during my college years.

Any academic and project cooperation intentions are welcome to contact me: macong[at]sensetime(dot)com / Cong-Reeshard.Ma[at]pku(dot)edu(dot)cn

<h2 style="text-align: left;">Experience</h2>
<html>
<body>
  <div class="container">
    <div class="image">
      <img src="http://reeshark.github.io/images/sensetime_icon.jpg" alt="A cute kitten" width="20%" height="20%">
  </div>
    <div class="text">
      <papertitle><strong>Sensetime (2021-present)</strong></papertitle>
      <br>
      Senior Researcher & Tech Adviser
      <br>
      <em><strong>Projects:</strong> Smart Transportation, Vehicle-Infrastructure, Smart Surveillance System</em>
      <br>
      <em><strong>Research Fields:</strong> 2D/Monocular3D/Lidar3D Detection, Multi-Object Tracking, Multi-Sensor Tracking</em>
    </div>
  </div>
</body>
</html>
  <style>
    .container {
      display: flex;
      align-items: center;
    }
        .icon {
      margin-right: 100px;
    }
  </style>



<h2 style="text-align: left;">Education</h2>

<h2 style="text-align: left;">Publication</h2>

<table>
<tbody>
<tr>
<td width="300px"><a href="http://reeshark.github.io/images/CVPR2024_holovic.png"><img src="http://reeshark.github.io/images/CVPR2024_holovic.png" alt="clean-usnob" width="100%" height="100%"></a></td>
<td width="75%" valign="middle">
<papertitle><strong>	
HoloVIC: Large-scale Dataset and Benchmark for Multi-Sensor Holographic Intersection and Vehicle-Infrastructure Cooperative</strong></papertitle>
<br>
<strong>Cong Ma</strong>, Qiao Lei, Chengkai Zhu, Kai Liu, Zelong Kong, Liqing, Xueqi Zhou, Yuheng KAN, Wei Wu
<br>
<em> <span style="color: blue;">The IEEE / CVF Computer Vision and Pattern Recognition Conference (CVPR), 2024 (Under Review)</span></em>
<p>Paper, Github, Benchmark</p>
</td>
</tr>
</tbody>
</table>

<table>
<tbody>
<tr>
<td width="300px"><a href="http://reeshark.github.io/images/CVPR2024_geopoint.png"><img src="http://reeshark.github.io/images/CVPR2024_geopoint.png" alt="clean-usnob" width="100%" height="100%"></a></td>
<td width="75%" valign="middle">
<papertitle><strong>GeoPoint: Geometry Point Embedding for 3D Object Detection with Fully Transformer</strong></papertitle>
<br>
Xin Jin*, Kai Liu*, <strong>Cong Ma*</strong>, Ruining Yang, Fei HUI, Wei Wu
<br>
<em> <span style="color: blue;">The IEEE / CVF Computer Vision and Pattern Recognition Conference (CVPR), 2024 (Under Review)</span></em>
<p>Paper, Github</p>
</td>
</tr>
</tbody>
</table>

<table>
<tbody>
<tr>
<td width="300px"><a href="http://reeshark.github.io/images/CVPR2024_dycpa.png"><img src="http://reeshark.github.io/images/CVPR2024_dycpa.png" alt="clean-usnob" width="100%" height="100%"></a></td>
<td width="75%" valign="middle">
<papertitle><strong>DyCPA: Online Constrainted Dynamic Clique Partitioning and Allocation Framework for Multi-Sensor Multi-Object Tracking</strong></papertitle>
<br>
Ruining Yang*, <strong>Cong Ma*</strong>, Kai Liu, Tianxiang Zhou, Xin Jin, Fei HUI, Wei Wu
<br>
<em> <span style="color: blue;">The IEEE / CVF Computer Vision and Pattern Recognition Conference (CVPR), 2024 (Under Review)</span></em>
</td>
</tr>
</tbody>
</table>

<table>
<tbody>
<tr>
<td width="300px"><a href="http://reeshark.github.io/images/CVPR2024_pigw.png"><img src="http://reeshark.github.io/images/CVPR2024_pigw.png" alt="clean-usnob" width="100%" height="100%"></a></td>
<td width="75%" valign="middle">
<papertitle><strong>PiGW: A Plug-in Generative Watermarking Framework</strong></papertitle>
<br>
Rui Ma, Mengxi Guo, Li Yuming, Hengyuan Zhang, <strong>Cong Ma</strong>, Yuan Li, Xiaodong Xie, Shanghang Zhang
<br>
<em> <span style="color: blue;">The IEEE / CVF Computer Vision and Pattern Recognition Conference (CVPR), 2024 (Under Review)</span></em>
</td>
</tr>
</tbody>
</table>

<table>
<tbody>
<tr>
<td width="300px"><a href="http://reeshark.github.io/images/Sensors2024.png"><img src="http://reeshark.github.io/images/Sensors2024.png" alt="clean-usnob" width="100%" height="100%"></a></td>
<td width="75%" valign="middle">
<papertitle><strong>Roadside Camera-LiDAR Calibration without Annotation</strong></papertitle>
<br>
Xiangmo Zhao, Shaojie Jin, <strong>Cong Ma*</strong>, Ying Gao, Fei Hui
<br>
<em> <span style="color: blue;">IEEE Sensors Journal, 2024 (Under Review)</span></em>
</td>
</tr>
</tbody>
</table>

<table>
<tbody>
<tr>
<td width="300px"><a href="http://reeshark.github.io/images/AAAI2024.png"><img src="http://reeshark.github.io/images/AAAI2024.png" alt="clean-usnob" width="100%" height="100%"></a></td>
<td width="75%" valign="middle">
<papertitle><strong>SwiftPillars High-efficiency Pillar Encoder for Lidar-based 3D Detection</strong></papertitle>
<br>
Xin Jin*, Kai Liu*, <strong>Cong Ma*</strong>, Ruining Yang, Fei Hui, Wei Wu,
<br>
<em> <span style="color: blue;">Association for the Advancement of Artificial Intelligence (AAAI), 2024</span></em> <p><a href="http://reeshark.github.io/files/SwiftPillars High-efficiency Pillar Encoder for Lidar-based 3D Detection, AAAI 2024.pdf">Paper</a></p>
</td>
</tr>
</tbody>
</table>


<table>
<tbody>
<tr>
<td width="300px"><a href="http://reeshark.github.io/images/IJCV2021_2.png"><img src="http://reeshark.github.io/images/IJCV2021_2.png" alt="clean-usnob" width="100%" height="100%"></a></td>
<td width="75%" valign="middle">
<papertitle><strong>Deep trajectory post-processing and position projection for single & multiple camera multiple object tracking</strong></papertitle>
<br>
<strong>Cong Ma</strong>, Fan Yang, Yuan Li, Huizhu Jia, Xiaodong Xie, Wen Gao
<br>
<em> <span style="color: blue;">International Journal of Computer Vision (IJCV), 2021</span></em> <p><a href="http://reeshark.github.io/files/Deep Trajectory Post-Processing and Position Projection for Single & Multiple Camera Multiple Object Tracking, International Journal of Computer Vision v2, 2021.pdf">Paper</a></p>
</td>
</tr>
</tbody>
</table>

<table>
<tbody>
<tr>
<td width="300px"><a href="http://reeshark.github.io/images/IJCV2021_1.png"><img src="http://reeshark.github.io/images/IJCV2021_1.png" alt="clean-usnob" width="100%" height="100%"></a></td>
<td width="75%" valign="middle">
<papertitle><strong>Deep human-interaction and association by graph-based learning for multiple object tracking in the wild</strong></papertitle>
<br>
<strong>Cong Ma</strong>, Fan Yang, Yuan Li, Huizhu Jia, Xiaodong Xie, Wen Gao
<br>
<em> <span style="color: blue;">International Journal of Computer Vision (IJCV), 2021</span></em> <p><a href="http://reeshark.github.io/files/Deep human-interaction and association by graph-based learning for multiple object tracking in the wild, International Journal of Computer Vision, 2021.pdf">Paper</a></p>
</td>
</tr>
</tbody>
</table>

<table>
<tbody>
<tr>
<td width="300px"><a href="http://reeshark.github.io/images/ICONIP2020.png"><img src="http://reeshark.github.io/images/ICONIP2020.png" alt="clean-usnob" width="100%" height="100%"></a></td>
<td width="75%" valign="middle">
<papertitle><strong>High-level task-driven single image deraining: Segmentation in rainy days</strong><span style="color: red;"> [Best Paper Nomination]</span></papertitle>
<br>
Mengxi Guo, Mingtao Chen, <strong>Cong Ma</strong>, Yuan Li, Xianfeng Li, Xiaodong Xie,
<br>
<em> <span style="color: blue;">The International Conference on Neural Information Processing (ICONIP), 2020</span></em> <p><a href="http://reeshark.github.io/files/High-level task-driven single image deraining Segmentation in rainy days, International Conference on Neural Information Processing, 2020.pdf">Paper</a></p>
</td>
</tr>
</tbody>
</table>

<table>
<tbody>
<tr>
<td width="300px"><a href="http://reeshark.github.io/images/ISCAS2020.png"><img src="http://reeshark.github.io/images/ISCAS2020.png" alt="clean-usnob" width="100%" height="100%"></a></td>
<td width="75%" valign="middle">
<papertitle><strong>Optical flow-guided mask generation network for video segmentation</strong></papertitle>
<br>
Yunyi Li, Fangping Chen, Fan Yang, <strong>Cong Ma</strong>, Yuan Li, Huizhu Jia, Xiaodong Xie,
<br>
<em> <span style="color: blue;">IEEE International Symposium on Circuits and Systems (ISCAS), 2020</span></em> <p><a href="http://reeshark.github.io/files/Optical flow-guided mask generation network for video segmentation, IEEE International Symposium on Circuits and Systems, 2020.pdf">Paper</a></p>
</td>
</tr>
</tbody>
</table>

<table>
<tbody>
<tr>
<td width="300px"><a href="http://reeshark.github.io/images/ICASSP2020.png"><img src="http://reeshark.github.io/images/ICASSP2020.png" alt="clean-usnob" width="100%" height="100%"></a></td>
<td width="75%" valign="middle">
<papertitle><strong>Bba-net: A bi-branch attention network for crowd counting</strong></papertitle>
<br>
Yi Hou, Chengyang Li, Fan Yang,<strong>Cong Ma</strong>, Liping Zhu, Yuan Li, Huizhu Jia, Xiaodong Xie,
<br>
<em> <span style="color: blue;">IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2020</span></em> <p><a href="http://reeshark.github.io/files/Bba-net A bi-branch attention network for crowd counting, IEEE International Conference on Acoustics, Speech and Signal Processing, 2020.pdf">Paper</a>, <a href="https://github.com/allenai/allenact">Github</a></p>
</td>
</tr>
</tbody>
</table>

 
<table>
<tbody>
<tr>
<td width="300px"><a href="http://reeshark.github.io/images/ICMR2019.png"><img src="http://reeshark.github.io/images/ICMR2019.png" alt="clean-usnob" width="100%" height="100%"></a></td>
<td width="75%" valign="middle">
<papertitle><strong>Deep association: End-to-end graph-based learning for multiple object tracking with conv-graph neural network</strong><span style="color: red;"> [Oral Presentation]</span></papertitle>
<br>
<strong>Cong Ma</strong>,
Yuan Li,
 Ziwei Zhang,
Yueqing Zhuang,
Huizhu Jia,
Xiaodong Xie,
<br>
<em> <span style="color: blue;">International Conference on Multimedia Retrieval (ICMR), 2019</span></em> <p><a href="http://reeshark.github.io/files/Deep association End-to-end graph-based learning for multiple object tracking with conv-graph neural network, International Conference on Multimedia Retrieval, 2019.pdf">Paper</a>, <a href="https://github.com/allenai/allenact">Github</a></p>
</td>
</tr>
</tbody>
</table>

<table>
<tbody>
<tr>
<td width="300px"><a href="http://reeshark.github.io/images/ICIP2018.png"><img src="http://reeshark.github.io/images/ICIP2018.png" alt="clean-usnob" width="100%" height="100%"></a></td>
<td width="75%" valign="middle">
<papertitle><strong>Dense relation network: Learning consistent and context-aware representation for semantic image segmentation</strong></papertitle>
<br>
Yueqing Zhuang, Fan Yang, Li Tao, <strong>Cong Ma</strong>, Ziwei Zhang, Yuan Li, Huizhu Jia, Xiaodong Xie, Wen Gao
<br>
<em> <span style="color: blue;">IEEE international conference on image processing (ICIP), 2018</span></em> <p><a href="http://reeshark.github.io/files/Dense relation network Learning consistent and context-aware representation for semantic image segmentation, 25th IEEE International Conference on Image Processing, 2018.pdf">Paper</a></p>
</td>
</tr>
</tbody>
</table>

<table>
<tbody>
<tr>
<td width="300px"><a href="http://reeshark.github.io/images/ICPR2018.png"><img src="http://reeshark.github.io/images/ICPR2018.png" alt="clean-usnob" width="100%" height="100%"></a></td>
<td width="75%" valign="middle">
<papertitle><strong>Relationnet: Learning deep-aligned representation for semantic image segmentation</strong></papertitle>
<br>
 Yueqing Zhuang,
 Li Tao,
 Fan Yang,
<strong>Cong Ma</strong>,
Ziwei Zhang,
Huizhu Jia,
Xiaodong Xie,
<br>
<em> <span style="color: blue;">International Conference on Pattern Recognition (ICPR), 2018</span></em> <p><a href="http://reeshark.github.io/files/RelationNet Learning deep-aligned representation for semantic image segmentation, 24th International Conference on Pattern Recognition, 2018.pdf">Paper</a></p>
</td>
</tr>
</tbody>
</table>

<table>
<tbody>
<tr>
<td width="300px"><a href="http://reeshark.github.io/images/ICME18.png"><img src="http://reeshark.github.io/images/ICME18.png" alt="clean-usnob" width="100%" height="100%"></a></td>
<td width="75%" valign="middle">
<papertitle><strong>Trajectory factory Tracklet cleaving and re-connection by deep siamese bi-gru for multiple object tracking</strong><span style="color: red;"> [Oral Presentation]</span></papertitle>
<br>
<strong>Cong Ma</strong>,
Changshui Yang,
Yueqing Zhuang,
Ziwei Zhang,
Huizhu Jia,
Xiaodong Xie,
<br>
<em> <span style="color: blue;">IEEE International Conference on Multimedia and Expo (ICME), 2018</span></em> <p><a href="http://reeshark.github.io/files/Trajectory factory Tracklet cleaving and re-connection by deep siamese bi-gru for multiple object tracking IEEE International Conference on Multimedia and Expo, 2018.pdf">Paper</a>, <a href="https://github.com/allenai/allenact">Github</a></p>
</td>
</tr>
</tbody>
</table>

<h2 style="text-align: left;">Awards and Honors</h2>

<h2 style="text-align: left;">Patents</h2>
