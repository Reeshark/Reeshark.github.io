---
permalink: /
title: "About Me"
excerpt: "Cong Ma (马璁)"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am Cong Ma (马璁), and I obtained my Ph.D. degree from [National Engineering Research Center of Visual Technology, Peking University](https://idm.pku.edu.cn/en) in 2021 advised by Prof. [Xiaidong Xie](https://scholar.google.com/citations?user=9-s2WI8AAAAJ&hl=en&oi=ao) and Prof. [Wen Gao](https://scholar.google.com/citations?user=u9aw5o8AAAAJ&hl=en&oi=ao). I completed my bachelor's degree at [School of Artificial Intelligence, Xidian University](https://sai.xidian.edu.cn/) in 2016 supervised by Prof. [Licheng Jiao](https://scholar.google.com/citations?user=FZbrL2YAAAAJ&hl=en&oi=ao). I received a visiting student researcher position at [Stanford Vision and Learning Lab](https://svl.stanford.edu/) under the supervision of Prof. [Silvio Savarese](https://scholar.google.com/citations?hl=en&user=ImpbxLsAAAAJ) in 2020. 

Currently, I am working at [SenseAuto](https://www.senseauto.com/) where I lead a team dedicated to researching the Roadside Holographic Intersection Perception Algorithm such as 2D/Monocular3D/Lidar3D Detection and Tracking, Multi-Sensor Tracking, Multi-Modality Representation, Trajectory Post-processing. Recently, I focus on World Model by using AIGC+LLM+3DGS to simulate data for Autonomous Driving Scenes. In addition to this role, I also serves as the Chief Technical Adviser for projects involving Smart-Surveillance Systems, Intelligent Transportation and Vehicle-Infrastructure Cooperation. I am leading a team consisting of two full-time employees, two internships, and six students, who are all dedicated to advancing the field of our projects. Together, we have been actively involved in cutting-edge research. 

In addition to my research contributions, I have served as a reviewer for prestigious journals and conferences, including IJCV, PR, TIP, TCSVT, AAAI, and ECCV and have reviewed a total of 24 papers. I was nominated for the prestigious ["Person of the Year"](http://stu.people.com.cn/GB/n1/2016/0429/c402103-28314575.html) award in 2016 during my college years.

Any academic and project cooperation intentions are welcome to contact me: macong[at]senseauto(dot)com / Cong-Reeshard.Ma[at]pku(dot)edu(dot)cn

<h2 style="text-align: left;">Experience</h2>
<html>
<head>
<style>
.container {
  display: flex;
  flex-direction: row;
  justify-content: center;
  align-items: center;
}

.image {
  width: 15%;
  height: 15%;
  margin: 0 auto;
}

.text {
  width: 80%;
  margin: 0 auto;
}
</style>
</head>
</html>

<html>
<body>
<div class="container" style="width:100%;">
<div class="image" style="width: 10%; height: 10%; float:left;">
<img src="http://reeshark.github.io/images/SenseAuto_logo.png">
</div>
<div class="text" style="width: 80%;float:right;">
<strong><font size = "3.5">SenseAuto (2022-present)</font></strong>
<br>
<font size = "2.5">Senior Researcher & Technical Adviser</font>
<br>
<em><font size = "2"><strong>Projects:</strong> Smart Transportation, Vehicle-Infrastructure Cooperation, World Model</font></em>
<br>
<em><font size = "2"><strong>Research Fields:</strong> 2D/Monocular3D/Lidar3D Detection and Tracking, Multi-Sensor Tracking, Multi-Modality Representation, Trajectory Post-processing, AIGC+LLM+3DGS </font></em>
</div>
</div>
</body>
</html>

<hr>
<html>
<body>
<div class="container" style="width:100%;">
<div class="image" style="width: 10%; height: 10%; float:left;">
<img src="http://reeshark.github.io/images/sensetime_icon.jpg">
</div>
<div class="text" style="width: 80%;float:right;">
<strong><font size = "3.5">Sensetime (2021-2022)</font></strong>
<br>
<font size = "2.5">Senior Researcher</font>
<br>
<em><font size = "2"><strong>Projects:</strong> AI CITY, Smart Surveillance System</font></em>
<br>
<em><font size = "2"><strong>Research Fields:</strong> Lidar3D Detection, Multi-Object Tracking, Multi-agent Interaction</font></em>
</div>
</div>
</body>
</html>
  
<hr>
<html>
<body>
<div class="container" style="width:100%;">
<div class="image" style="width: 10%; height: 10%; float:left;">
<img src="http://reeshark.github.io/images/stanford.jpg">
</div>
<div class="text" style="width: 80%;float:right;">
<strong><font size = "3.5">Stanford University (2020-2021)</font></strong>
<br>
<font size = "2.5">Visiting Student Researcher (Remote, due to Covid-19)</font>
<br>
<em><font size = "2"><strong>Projects:</strong> JackRabbot </font></em>
<br>
<em><font size = "2"><strong>Research Fields:</strong> Lidar3D Detection, Multi-Object Tracking</font></em>
</div>
</div>
</body>
</html>
  
<hr>
<html>
<body>
<div class="container" style="width:100%;">
<div class="image" style="width: 10%; height: 10%; float:left;">
<img src="http://reeshark.github.io/images/aibee.png">
</div>
<div class="text" style="width: 80%;float:right;">
<strong><font size = "3.5">Aibee (2018-2019)</font></strong>
<br>
<font size = "2.5">Research Intern</font>
<br>
<em><font size = "2"><strong>Projects: </strong>Smart Shopping Mall</font></em>
<br>
<em><font size = "2"><strong>Research Fields:</strong> Multi-Object Tracking, Person Re-identification</font></em>
</div>
</div>
</body>
</html>


<h2 style="text-align: left;">Education</h2>
<html>
<body>
<div class="container" style="width:100%;">
<div class="image" style="width: 10%; height: 10%; float:left;">
<img src="http://reeshark.github.io/images/pku.png">
</div>
<div class="text" style="width: 80%;float:right;">
<strong><font size = "3.5">Peking University (2016-2021)</font></strong>
<br>
<font size = "2.5">Ph.D. (Computer Applied Technology)</font>
<br>
<em><font size = "2"><strong>Projects: </strong> Smart City, Intelligent Park</font></em>
<br>
<em><font size = "2"><strong>Research Fields:</strong> Multi-Object Tracking, Segmentation, Person Re-identification</font></em>
</div>
</div>
</body>
</html>

<hr>
<html>
<body>
<div class="container" style="width:100%;">
<div class="image" style="width: 10%; height: 10%; float:left;">
<img src="http://reeshark.github.io/images/xidian.jpeg">
</div>
<div class="text" style="width: 80%;float:right;">
<strong><font size = "3.5">Xidian University (2012-2016)</font></strong>
<br>
<font size = "2.5">Bachelor of Engineering (Articial Intelligence)</font>
<br>
<em><font size = "2"><strong>Projects:</strong> Wise-wheelchair, Smart Spinning</font></em>
<br>
<em><font size = "2"><strong>Research Fields:</strong> View Synthesis, Virual Reality, BrainWave Recognition</font></em>
</div>
</div>
</body>
</html>

<h2 style="text-align: left;">Publication</h2>



<table>
<tbody>
<tr>
<td width="300px"><a href="http://reeshark.github.io/images/CVPR2024_geopoint.png"><img src="http://reeshark.github.io/images/CVPR2024_geopoint.png" alt="clean-usnob" width="100%" height="100%"></a></td>
<td width="75%" valign="middle">
<papertitle><strong>GeoPoint: Geometry Point Embedding for 3D Object Detection with Fully Transformer</strong></papertitle>
<br>
Xin Jin*, Kai Liu*, <strong>Cong Ma*</strong>, Ruining Yang, Fei HUI, Wei Wu
<br>
<em> <span style="color: blue;">European Conference on Computer Vision (ECCV), 2024 (Under Review)</span></em>
<p>Paper, Github</p>
</td>
</tr>
</tbody>
</table>

<table>
<tbody>
<tr>
<td width="300px"><a href="http://reeshark.github.io/images/CVPR2024_dycpa.png"><img src="http://reeshark.github.io/images/CVPR2024_dycpa.png" alt="clean-usnob" width="100%" height="100%"></a></td>
<td width="75%" valign="middle">
<papertitle><strong>DyCPA: Online Constrainted Dynamic Clique Partitioning and Allocation Framework for Multi-Sensor Multi-Object Tracking</strong></papertitle>
<br>
Ruining Yang*, <strong>Cong Ma*</strong>, Kai Liu, Tianxiang Zhou, Xin Jin, Fei HUI, Wei Wu
<br>
<em> <span style="color: blue;">European Conference on Computer Vision (ECCV), 2024 (Under Review)</span></em>
</td>
</tr>
</tbody>
</table>

<table>
<tbody>
<tr>
<td width="300px"><a href="http://reeshark.github.io/images/CVPR2024_pigw.png"><img src="http://reeshark.github.io/images/CVPR2024_pigw.png" alt="clean-usnob" width="100%" height="100%"></a></td>
<td width="75%" valign="middle">
<papertitle><strong>PiGW: A Plug-in Generative Watermarking Framework</strong></papertitle>
<br>
Rui Ma, Mengxi Guo, Li Yuming, Hengyuan Zhang, <strong>Cong Ma</strong>, Yuan Li, Xiaodong Xie, Shanghang Zhang
<br>
<em> <span style="color: blue;">European Conference on Computer Vision (ECCV), 2024 (Under Review)</span></em>
</td>
</tr>
</tbody>
</table>

<table>
<tbody>
<tr>
<td width="300px"><a href="http://reeshark.github.io/images/CVPR2024_holovic.png"><img src="http://reeshark.github.io/images/CVPR2024_holovic.png" alt="clean-usnob" width="100%" height="100%"></a></td>
<td width="75%" valign="middle">
<papertitle><strong>	
HoloVIC: Large-scale Dataset and Benchmark for Multi-Sensor Holographic Intersection and Vehicle-Infrastructure Cooperative</strong></papertitle>
<br>
<strong>Cong Ma</strong>, Qiao Lei, Chengkai Zhu, Kai Liu, Zelong Kong, Liqing, Xueqi Zhou, Yuheng KAN, Wei Wu
<br>
<em> <span style="color: blue;">The IEEE / CVF Computer Vision and Pattern Recognition Conference (CVPR), 2024</span></em>
<p><a href="https://arxiv.org/abs/2403.02640">Paper</a></p>
<p><a>Paper</a></p>
<p><a href="holvic.net">Benchmark</a></p>
</td>
</tr>
</tbody>
</table>

<table>
<tbody>
<tr>
<td width="300px"><a href="http://reeshark.github.io/images/Sensors2024.png"><img src="http://reeshark.github.io/images/Sensors2024.png" alt="clean-usnob" width="100%" height="100%"></a></td>
<td width="75%" valign="middle">
<papertitle><strong>Roadside Camera-LiDAR Calibration without Annotation</strong></papertitle>
<br>
Xiangmo Zhao, Shaojie Jin, <strong>Cong Ma</strong>, Ying Gao, Fei Hui
<br>
<em> <span style="color: blue;">IEEE Sensors Journal, 2024</span></em>
</td>
</tr>
</tbody>
</table>

<table>
<tbody>
<tr>
<td width="300px"><a href="http://reeshark.github.io/images/AAAI2024.png"><img src="http://reeshark.github.io/images/AAAI2024.png" alt="clean-usnob" width="100%" height="100%"></a></td>
<td width="75%" valign="middle">
<papertitle><strong>SwiftPillars High-efficiency Pillar Encoder for Lidar-based 3D Detection</strong></papertitle>
<br>
Xin Jin*, Kai Liu*, <strong>Cong Ma*</strong>, Ruining Yang, Fei Hui, Wei Wu,
<br>
<em> <span style="color: blue;">Association for the Advancement of Artificial Intelligence (AAAI), 2024</span></em> <p><a href="http://reeshark.github.io/files/SwiftPillars High-efficiency Pillar Encoder for Lidar-based 3D Detection, AAAI 2024.pdf">Paper</a></p>
</td>
</tr>
</tbody>
</table>


<table>
<tbody>
<tr>
<td width="300px"><a href="http://reeshark.github.io/images/IJCV2021_2.png"><img src="http://reeshark.github.io/images/IJCV2021_2.png" alt="clean-usnob" width="100%" height="100%"></a></td>
<td width="75%" valign="middle">
<papertitle><strong>Deep trajectory post-processing and position projection for single & multiple camera multiple object tracking</strong></papertitle>
<br>
<strong>Cong Ma</strong>, Fan Yang, Yuan Li, Huizhu Jia, Xiaodong Xie, Wen Gao
<br>
<em> <span style="color: blue;">International Journal of Computer Vision (IJCV), 2021</span></em> <p><a href="http://reeshark.github.io/files/Deep Trajectory Post-Processing and Position Projection for Single & Multiple Camera Multiple Object Tracking, International Journal of Computer Vision v2, 2021.pdf">Paper</a></p>
</td>
</tr>
</tbody>
</table>

<table>
<tbody>
<tr>
<td width="300px"><a href="http://reeshark.github.io/images/IJCV2021_1.png"><img src="http://reeshark.github.io/images/IJCV2021_1.png" alt="clean-usnob" width="100%" height="100%"></a></td>
<td width="75%" valign="middle">
<papertitle><strong>Deep human-interaction and association by graph-based learning for multiple object tracking in the wild</strong></papertitle>
<br>
<strong>Cong Ma</strong>, Fan Yang, Yuan Li, Huizhu Jia, Xiaodong Xie, Wen Gao
<br>
<em> <span style="color: blue;">International Journal of Computer Vision (IJCV), 2021</span></em> <p><a href="http://reeshark.github.io/files/Deep human-interaction and association by graph-based learning for multiple object tracking in the wild, International Journal of Computer Vision, 2021.pdf">Paper</a></p>
</td>
</tr>
</tbody>
</table>

<table>
<tbody>
<tr>
<td width="300px"><a href="http://reeshark.github.io/images/ICONIP2020.png"><img src="http://reeshark.github.io/images/ICONIP2020.png" alt="clean-usnob" width="100%" height="100%"></a></td>
<td width="75%" valign="middle">
<papertitle><strong>High-level task-driven single image deraining: Segmentation in rainy days</strong><span style="color: red;"> [Best Paper Nomination]</span></papertitle>
<br>
Mengxi Guo, Mingtao Chen, <strong>Cong Ma</strong>, Yuan Li, Xianfeng Li, Xiaodong Xie,
<br>
<em> <span style="color: blue;">The International Conference on Neural Information Processing (ICONIP), 2020</span></em> <p><a href="http://reeshark.github.io/files/High-level task-driven single image deraining Segmentation in rainy days, International Conference on Neural Information Processing, 2020.pdf">Paper</a></p>
</td>
</tr>
</tbody>
</table>

<table>
<tbody>
<tr>
<td width="300px"><a href="http://reeshark.github.io/images/ISCAS2020.png"><img src="http://reeshark.github.io/images/ISCAS2020.png" alt="clean-usnob" width="100%" height="100%"></a></td>
<td width="75%" valign="middle">
<papertitle><strong>Optical flow-guided mask generation network for video segmentation</strong></papertitle>
<br>
Yunyi Li, Fangping Chen, Fan Yang, <strong>Cong Ma</strong>, Yuan Li, Huizhu Jia, Xiaodong Xie,
<br>
<em> <span style="color: blue;">IEEE International Symposium on Circuits and Systems (ISCAS), 2020</span></em> <p><a href="http://reeshark.github.io/files/Optical flow-guided mask generation network for video segmentation, IEEE International Symposium on Circuits and Systems, 2020.pdf">Paper</a></p>
</td>
</tr>
</tbody>
</table>

<table>
<tbody>
<tr>
<td width="300px"><a href="http://reeshark.github.io/images/ICASSP2020.png"><img src="http://reeshark.github.io/images/ICASSP2020.png" alt="clean-usnob" width="100%" height="100%"></a></td>
<td width="75%" valign="middle">
<papertitle><strong>Bba-net: A bi-branch attention network for crowd counting</strong></papertitle>
<br>
Yi Hou, Chengyang Li, Fan Yang,<strong>Cong Ma</strong>, Liping Zhu, Yuan Li, Huizhu Jia, Xiaodong Xie,
<br>
<em> <span style="color: blue;">IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2020</span></em> <p><a href="http://reeshark.github.io/files/Bba-net A bi-branch attention network for crowd counting, IEEE International Conference on Acoustics, Speech and Signal Processing, 2020.pdf">Paper</a>, <a href="https://github.com/allenai/allenact">Github</a></p>
</td>
</tr>
</tbody>
</table>

 
<table>
<tbody>
<tr>
<td width="300px"><a href="http://reeshark.github.io/images/ICMR2019.png"><img src="http://reeshark.github.io/images/ICMR2019.png" alt="clean-usnob" width="100%" height="100%"></a></td>
<td width="75%" valign="middle">
<papertitle><strong>Deep association: End-to-end graph-based learning for multiple object tracking with conv-graph neural network</strong><span style="color: red;"> [Oral Presentation]</span></papertitle>
<br>
<strong>Cong Ma</strong>,
Yuan Li,
 Ziwei Zhang,
Yueqing Zhuang,
Huizhu Jia,
Xiaodong Xie,
<br>
<em> <span style="color: blue;">International Conference on Multimedia Retrieval (ICMR), 2019</span></em> <p><a href="http://reeshark.github.io/files/Deep association End-to-end graph-based learning for multiple object tracking with conv-graph neural network, International Conference on Multimedia Retrieval, 2019.pdf">Paper</a>, <a href="https://github.com/allenai/allenact">Github</a></p>
</td>
</tr>
</tbody>
</table>

<table>
<tbody>
<tr>
<td width="300px"><a href="http://reeshark.github.io/images/ICIP2018.png"><img src="http://reeshark.github.io/images/ICIP2018.png" alt="clean-usnob" width="100%" height="100%"></a></td>
<td width="75%" valign="middle">
<papertitle><strong>Dense relation network: Learning consistent and context-aware representation for semantic image segmentation</strong></papertitle>
<br>
Yueqing Zhuang, Fan Yang, Li Tao, <strong>Cong Ma</strong>, Ziwei Zhang, Yuan Li, Huizhu Jia, Xiaodong Xie, Wen Gao
<br>
<em> <span style="color: blue;">IEEE international conference on image processing (ICIP), 2018</span></em> <p><a href="http://reeshark.github.io/files/Dense relation network Learning consistent and context-aware representation for semantic image segmentation, 25th IEEE International Conference on Image Processing, 2018.pdf">Paper</a></p>
</td>
</tr>
</tbody>
</table>

<table>
<tbody>
<tr>
<td width="300px"><a href="http://reeshark.github.io/images/ICPR2018.png"><img src="http://reeshark.github.io/images/ICPR2018.png" alt="clean-usnob" width="100%" height="100%"></a></td>
<td width="75%" valign="middle">
<papertitle><strong>Relationnet: Learning deep-aligned representation for semantic image segmentation</strong></papertitle>
<br>
 Yueqing Zhuang,
 Li Tao,
 Fan Yang,
<strong>Cong Ma</strong>,
Ziwei Zhang,
Huizhu Jia,
Xiaodong Xie,
<br>
<em> <span style="color: blue;">International Conference on Pattern Recognition (ICPR), 2018</span></em> <p><a href="http://reeshark.github.io/files/RelationNet Learning deep-aligned representation for semantic image segmentation, 24th International Conference on Pattern Recognition, 2018.pdf">Paper</a></p>
</td>
</tr>
</tbody>
</table>

<table>
<tbody>
<tr>
<td width="300px"><a href="http://reeshark.github.io/images/ICME18.png"><img src="http://reeshark.github.io/images/ICME18.png" alt="clean-usnob" width="100%" height="100%"></a></td>
<td width="75%" valign="middle">
<papertitle><strong>Trajectory factory Tracklet cleaving and re-connection by deep siamese bi-gru for multiple object tracking</strong><span style="color: red;"> [Oral Presentation]</span></papertitle>
<br>
<strong>Cong Ma</strong>,
Changshui Yang,
Yueqing Zhuang,
Ziwei Zhang,
Huizhu Jia,
Xiaodong Xie,
<br>
<em> <span style="color: blue;">IEEE International Conference on Multimedia and Expo (ICME), 2018</span></em> <p><a href="http://reeshark.github.io/files/Trajectory factory Tracklet cleaving and re-connection by deep siamese bi-gru for multiple object tracking IEEE International Conference on Multimedia and Expo, 2018.pdf">Paper</a>, <a href="https://github.com/allenai/allenact">Github</a></p>
</td>
</tr>
</tbody>
</table>

<h2 style="text-align: left;">Awards and Honors</h2>

<html>
<body>
<em><font size = "2">1.<a href="http://stu.people.com.cn/GB/n1/2016/0429/c402103-28314575.html">The 11th “Person of the Year” for college student nomination in 2016</a></font></em>
<br>
<em><font size = "2">  &nbsp;&nbsp;2016年第十一届大学生“年度人物“候选</font></em>
<br>
<em><font size = "2">2.<a href="https://baike.baidu.com/pic/%E9%A9%AC%E7%92%81/3083016/11/b2de9c82d158ccbff68d820114d8bc3eb13541d3?fr=lemma&fromModule=lemma_content-image#aid=11&pic=b2de9c82d158ccbff68d820114d8bc3eb13541d3">Meritorious Winner on Interdisciplinary Contest In Modeling Certificate of Achievement, in 2015</a></font></em>
<br>
<em><font size = "2">  &nbsp;&nbsp;美国大学生数学建模大赛一等奖</font></em>

<br>
<em><font size = "2">3.<a href="https://baike.baidu.com/pic/%E9%A9%AC%E7%92%81/3083016/11/b2de9c82d158ccbff68d820114d8bc3eb13541d3?fr=lemma&fromModule=lemma_content-image#aid=11&pic=b3b7d0a20cf431ad4fda97024636acaf2edd9885">The First Prize on “National Challenge Cup” in 2016</a></font></em>
<br>
<em><font size = "2">  &nbsp;&nbsp;第十四届“挑战杯”全国大学生课外学术科技作品竞赛一等奖</font></em>

<br>
<em><font size = "2">4.<a href="https://baike.baidu.com/pic/%E9%A9%AC%E7%92%81/3083016/11/b2de9c82d158ccbff68d820114d8bc3eb13541d3?fr=lemma&fromModule=lemma_content-image#aid=11&pic=fc1f4134970a304ee28e77c1dcc8a786c9175c59">The Excellent Award on “Innovation and Entrepreneurship Training Program” in 2014</a></font></em>
<br>
<em><font size = "2">  &nbsp;&nbsp; 国家创新创业训练计划项目优秀作品</font></em>


<br>
<em><font size = "2">5.<a href="https://baike.baidu.com/pic/%E9%A9%AC%E7%92%81/3083016/11/b2de9c82d158ccbff68d820114d8bc3eb13541d3?fr=lemma&fromModule=lemma_content-image#aid=11&pic=b8389b504fc2d562135106d6ea1190ef76c66cb4">The Winning Prize on “Parallel Application Challenge” in 2014</a></font></em>
<br>
<em><font size = "2">  &nbsp;&nbsp;2014年并行应用挑战赛优胜奖</font></em>

<br>
<em><font size = "2">6.<a href="https://baike.baidu.com/pic/%E9%A9%AC%E7%92%81/3083016/11/b2de9c82d158ccbff68d820114d8bc3eb13541d3?fr=lemma&fromModule=lemma_content-image#aid=11&pic=f9dcd100baa1cd11c7e4441bb412c8fcc3ce2dbe">National High School Applied Physics Competition Third Prize</a></font></em>
<br>
<em><font size = "2">  &nbsp;&nbsp;全国高中应用物理竞赛三等奖</font></em>
<br>
<em><font size = "2">7.<a href="https://baike.baidu.com/pic/%E9%A9%AC%E7%92%81/3083016/11/b2de9c82d158ccbff68d820114d8bc3eb13541d3?fr=lemma&fromModule=lemma_content-image#aid=11&pic=4a36acaf2edda3cc1be5891b0ce93901213f9283">First Prize of World Junior Olympiad Mathematics Competition in Beijing Division </a></font></em>
<br>
<em><font size = "2">  &nbsp;&nbsp;世界少年奥林匹克数学竞赛北京赛区一等奖</font></em>

</body>
</html>



<h2 style="text-align: left;">Patents</h2>
<em><font size = "2"> 1.<strong>Virtual View Synthesis Method and Device</strong>, Patent No.: CN106162137B, <br>Inventors: Changshui Yang, Huizhu Jia, <strong>Cong Ma</strong>, Xiaodong Xie, Chen Rui</font></em>
<br>
<em><font size = "2"> 2.<strong>Image denoising method and image denoising device</strong>, Patent No.: CN106162137A, <br>Inventors: Changshui Yang, <strong>Cong Ma</strong>, Huizhu Jia, Xiaodong Xie, Rui Chen, Wen Gao</font></em>
<br>
<em><font size = "2"> 3.<strong>A Stereoscopic Image Acquisition Device</strong>, Patent No.: CN202043213U, <br>Inventor: <strong>Cong Ma</strong></font></em>
<br>
<em><font size = "2"> 4.<strong>A Wheelchair Controlled by Eye-Tracking</strong>, Patent No.: CN204863717U, <br>Inventor: <strong>Cong Ma</strong>, Yi Zhu, Yanfang Guo, Jingyan Geng</font></em>
<br>
<em><font size = "2"> 5.<strong>Multifunctional Somatosensory Synchronous Bicycle Fitness and Entertainment System</strong>, Patent No.: CN204073263U, <br>Inventors: Yi Zhu, <strong>Cong Ma</strong>, Yicong Cao</font></em>
<br>


